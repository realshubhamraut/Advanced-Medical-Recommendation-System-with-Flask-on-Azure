{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11848,"databundleVersionId":862157,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objs as go\nimport copy\nimport os\nimport torch\nfrom PIL import Image\nfrom PIL import Image, ImageDraw\nfrom torch.utils.data import Dataset\nimport torchvision.transforms as transforms\nfrom torch.utils.data import random_split\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport torch.nn as nn\nfrom torchvision import utils\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:52:58.571098Z","iopub.execute_input":"2025-02-24T01:52:58.571353Z","iopub.status.idle":"2025-02-24T01:53:04.903913Z","shell.execute_reply.started":"2025-02-24T01:52:58.571322Z","shell.execute_reply":"2025-02-24T01:53:04.903035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# library which allows us to view model summary like keras/tf\n!pip install torchsummary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:04.904831Z","iopub.execute_input":"2025-02-24T01:53:04.905285Z","iopub.status.idle":"2025-02-24T01:53:09.013062Z","shell.execute_reply.started":"2025-02-24T01:53:04.905254Z","shell.execute_reply":"2025-02-24T01:53:09.012246Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels_df = pd.read_csv('/kaggle/input/histopathologic-cancer-detection/train_labels.csv')\nprint(labels_df.head().to_markdown())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:09.014070Z","iopub.execute_input":"2025-02-24T01:53:09.014387Z","iopub.status.idle":"2025-02-24T01:53:09.388863Z","shell.execute_reply.started":"2025-02-24T01:53:09.014362Z","shell.execute_reply":"2025-02-24T01:53:09.387985Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.listdir('/kaggle/input/histopathologic-cancer-detection/')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:09.390677Z","iopub.execute_input":"2025-02-24T01:53:09.390919Z","iopub.status.idle":"2025-02-24T01:53:09.398809Z","shell.execute_reply.started":"2025-02-24T01:53:09.390899Z","shell.execute_reply":"2025-02-24T01:53:09.398099Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:09.400260Z","iopub.execute_input":"2025-02-24T01:53:09.400550Z","iopub.status.idle":"2025-02-24T01:53:09.412698Z","shell.execute_reply.started":"2025-02-24T01:53:09.400528Z","shell.execute_reply":"2025-02-24T01:53:09.412051Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# No duplicate ids found\nlabels_df[labels_df.duplicated(keep=False)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:09.413418Z","iopub.execute_input":"2025-02-24T01:53:09.413651Z","iopub.status.idle":"2025-02-24T01:53:09.519412Z","shell.execute_reply.started":"2025-02-24T01:53:09.413619Z","shell.execute_reply":"2025-02-24T01:53:09.518486Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels_df['label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:09.520355Z","iopub.execute_input":"2025-02-24T01:53:09.520707Z","iopub.status.idle":"2025-02-24T01:53:09.530797Z","shell.execute_reply.started":"2025-02-24T01:53:09.520665Z","shell.execute_reply":"2025-02-24T01:53:09.530015Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"imgpath =\"/kaggle/input/histopathologic-cancer-detection/train/\" # training data is stored in this folder\nmalignant = labels_df.loc[labels_df['label']==1]['id'].values    # get the ids of malignant cases\nnormal = labels_df.loc[labels_df['label']==0]['id'].values       # get the ids of the normal cases\n\nprint('normal ids')\nprint(normal[0:3],'\\n')\n\nprint('malignant ids')\nprint(malignant[0:3])","metadata":{"_kg_hide-input":true,"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:09.531656Z","iopub.execute_input":"2025-02-24T01:53:09.531934Z","iopub.status.idle":"2025-02-24T01:53:09.714455Z","shell.execute_reply.started":"2025-02-24T01:53:09.531904Z","shell.execute_reply":"2025-02-24T01:53:09.713767Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_fig(ids,title,nrows=5,ncols=15):\n\n    fig,ax = plt.subplots(nrows,ncols,figsize=(18,6))\n    plt.subplots_adjust(wspace=0, hspace=0) \n    for i,j in enumerate(ids[:nrows*ncols]):\n        fname = os.path.join(imgpath ,j +'.tif')\n        img = Image.open(fname)\n        idcol = ImageDraw.Draw(img)\n        idcol.rectangle(((0,0),(95,95)),outline='white')\n        plt.subplot(nrows, ncols, i+1) \n        plt.imshow(np.array(img))\n        plt.axis('off')\n\n    plt.suptitle(title, y=0.94)","metadata":{"_kg_hide-input":true,"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:09.715263Z","iopub.execute_input":"2025-02-24T01:53:09.715581Z","iopub.status.idle":"2025-02-24T01:53:09.720760Z","shell.execute_reply.started":"2025-02-24T01:53:09.715549Z","shell.execute_reply":"2025-02-24T01:53:09.719973Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_fig(malignant,'Malignant Cases')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:09.721508Z","iopub.execute_input":"2025-02-24T01:53:09.721780Z","iopub.status.idle":"2025-02-24T01:53:12.467578Z","shell.execute_reply.started":"2025-02-24T01:53:09.721760Z","shell.execute_reply":"2025-02-24T01:53:12.466678Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_fig(normal,'Non-Malignant Cases')","metadata":{"_kg_hide-input":true,"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:12.468563Z","iopub.execute_input":"2025-02-24T01:53:12.468851Z","iopub.status.idle":"2025-02-24T01:53:15.050529Z","shell.execute_reply.started":"2025-02-24T01:53:12.468828Z","shell.execute_reply":"2025-02-24T01:53:15.047653Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.manual_seed(0) # fix random seed\n\nclass pytorch_data(Dataset):\n    \n    def __init__(self,data_dir,transform,data_type=\"train\"):      \n    \n        # Get Image File Names\n        cdm_data=os.path.join(data_dir,data_type)  # directory of files\n        \n        file_names = os.listdir(cdm_data) # get list of images in that directory  \n        idx_choose = np.random.choice(np.arange(len(file_names)), \n                                      4000,\n                                      replace=False).tolist()\n        file_names_sample = [file_names[x] for x in idx_choose]\n        self.full_filenames = [os.path.join(cdm_data, f) for f in file_names_sample]   # get the full path to images\n        \n        # Get Labels\n        labels_data=os.path.join(data_dir,\"train_labels.csv\") \n        labels_df=pd.read_csv(labels_data)\n        labels_df.set_index(\"id\", inplace=True) # set data frame index to id\n        self.labels = [labels_df.loc[filename[:-4]].values[0] for filename in file_names_sample]  # obtained labels from df\n        self.transform = transform\n      \n    def __len__(self):\n        return len(self.full_filenames) # size of dataset\n      \n    def __getitem__(self, idx):\n        # open image, apply transforms and return with label\n        image = Image.open(self.full_filenames[idx])  # Open Image with PIL\n        image = self.transform(image) # Apply Specific Transformation to Image\n        return image, self.labels[idx]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:15.051572Z","iopub.execute_input":"2025-02-24T01:53:15.051912Z","iopub.status.idle":"2025-02-24T01:53:15.065850Z","shell.execute_reply.started":"2025-02-24T01:53:15.051882Z","shell.execute_reply":"2025-02-24T01:53:15.065083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# define transformation that converts a PIL image into PyTorch tensors\nimport torchvision.transforms as transforms\ndata_transformer = transforms.Compose([transforms.ToTensor(),\n                                       transforms.Resize((46,46))])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:15.069510Z","iopub.execute_input":"2025-02-24T01:53:15.069756Z","iopub.status.idle":"2025-02-24T01:53:15.074962Z","shell.execute_reply.started":"2025-02-24T01:53:15.069736Z","shell.execute_reply":"2025-02-24T01:53:15.074088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define an object of the custom dataset for the train folder.\ndata_dir = '/kaggle/input/histopathologic-cancer-detection/'\nimg_dataset = pytorch_data(data_dir, data_transformer, \"train\") # Histopathalogic images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:15.076873Z","iopub.execute_input":"2025-02-24T01:53:15.077106Z","iopub.status.idle":"2025-02-24T01:53:16.538824Z","shell.execute_reply.started":"2025-02-24T01:53:15.077086Z","shell.execute_reply":"2025-02-24T01:53:16.538126Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# load an example tensor\nimg,label=img_dataset[10]\nprint(img.shape,torch.min(img),torch.max(img))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:16.539694Z","iopub.execute_input":"2025-02-24T01:53:16.539906Z","iopub.status.idle":"2025-02-24T01:53:16.650163Z","shell.execute_reply.started":"2025-02-24T01:53:16.539887Z","shell.execute_reply":"2025-02-24T01:53:16.649332Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len_img=len(img_dataset)\nlen_train=int(0.8*len_img)\nlen_val=len_img-len_train\n\n# Split Pytorch tensor\ntrain_ts,val_ts=random_split(img_dataset,\n                             [len_train,len_val]) # random split 80/20\n\nprint(\"train dataset size:\", len(train_ts))\nprint(\"validation dataset size:\", len(val_ts))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:16.650924Z","iopub.execute_input":"2025-02-24T01:53:16.651132Z","iopub.status.idle":"2025-02-24T01:53:16.660085Z","shell.execute_reply.started":"2025-02-24T01:53:16.651112Z","shell.execute_reply":"2025-02-24T01:53:16.659408Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# getting the torch tensor image & target variable\nii=-1\nfor x,y in train_ts:\n    print(x.shape,y)\n    ii+=1\n    if(ii>5):\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:16.660857Z","iopub.execute_input":"2025-02-24T01:53:16.661081Z","iopub.status.idle":"2025-02-24T01:53:16.720193Z","shell.execute_reply.started":"2025-02-24T01:53:16.661061Z","shell.execute_reply":"2025-02-24T01:53:16.719484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import plotly.express as px\n\ndef plot_img(x,y,title=None):\n\n    npimg = x.numpy() # convert tensor to numpy array\n    npimg_tr=np.transpose(npimg, (1,2,0)) # Convert to H*W*C shape\n    fig = px.imshow(npimg_tr)\n    fig.update_layout(template='plotly_white')\n    fig.update_layout(title=title,height=300,margin={'l':10,'r':20,'b':10})\n    fig.show()","metadata":{"_kg_hide-input":true,"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:16.720928Z","iopub.execute_input":"2025-02-24T01:53:16.721124Z","iopub.status.idle":"2025-02-24T01:53:17.373513Z","shell.execute_reply.started":"2025-02-24T01:53:16.721105Z","shell.execute_reply":"2025-02-24T01:53:17.372847Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create grid of sample images \ngrid_size=30\nrnd_inds=np.random.randint(0,len(train_ts),grid_size)\nprint(\"image indices:\",rnd_inds)\n\nx_grid_train=[train_ts[i][0] for i in rnd_inds]\ny_grid_train=[train_ts[i][1] for i in rnd_inds]\n\nx_grid_train=utils.make_grid(x_grid_train, nrow=10, padding=2)\nprint(x_grid_train.shape)\n    \nplot_img(x_grid_train,y_grid_train,'Training Subset Examples')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:17.374181Z","iopub.execute_input":"2025-02-24T01:53:17.374389Z","iopub.status.idle":"2025-02-24T01:53:19.253822Z","shell.execute_reply.started":"2025-02-24T01:53:17.374370Z","shell.execute_reply":"2025-02-24T01:53:19.253057Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"grid_size=30\nrnd_inds=np.random.randint(0,len(val_ts),grid_size)\nprint(\"image indices:\",rnd_inds)\nx_grid_val=[val_ts[i][0] for i in range(grid_size)]\ny_grid_val=[val_ts[i][1] for i in range(grid_size)]\n\nx_grid_val=utils.make_grid(x_grid_val, nrow=10, padding=2)\nprint(x_grid_val.shape)\n\nplot_img(x_grid_val,y_grid_val,'Validation Dataset Preview')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:19.254430Z","iopub.execute_input":"2025-02-24T01:53:19.254717Z","iopub.status.idle":"2025-02-24T01:53:19.576661Z","shell.execute_reply.started":"2025-02-24T01:53:19.254682Z","shell.execute_reply":"2025-02-24T01:53:19.575692Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the following transformations for the training dataset\ntr_transf = transforms.Compose([\n#     transforms.Resize((40,40)),\n    transforms.RandomHorizontalFlip(p=0.5), \n    transforms.RandomVerticalFlip(p=0.5),  \n    transforms.RandomRotation(45),         \n#     transforms.RandomResizedCrop(50,scale=(0.8,1.0),ratio=(1.0,1.0)),\n    transforms.ToTensor()])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:19.577527Z","iopub.execute_input":"2025-02-24T01:53:19.577809Z","iopub.status.idle":"2025-02-24T01:53:19.581842Z","shell.execute_reply.started":"2025-02-24T01:53:19.577786Z","shell.execute_reply":"2025-02-24T01:53:19.581104Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# For the validation dataset, we don't need any augmentation; simply convert images into tensors\nval_transf = transforms.Compose([\n    transforms.ToTensor()])\n\n# After defining the transformations, overwrite the transform functions of train_ts, val_ts\ntrain_ts.transform=tr_transf\nval_ts.transform=val_transf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:19.582753Z","iopub.execute_input":"2025-02-24T01:53:19.582979Z","iopub.status.idle":"2025-02-24T01:53:19.598421Z","shell.execute_reply.started":"2025-02-24T01:53:19.582959Z","shell.execute_reply":"2025-02-24T01:53:19.597593Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# The subset can also have transform attribute (if we asign)\ntrain_ts.transform","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:19.599265Z","iopub.execute_input":"2025-02-24T01:53:19.599537Z","iopub.status.idle":"2025-02-24T01:53:19.618134Z","shell.execute_reply.started":"2025-02-24T01:53:19.599517Z","shell.execute_reply":"2025-02-24T01:53:19.617440Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Training DataLoader\ntrain_dl = DataLoader(train_ts,\n                      batch_size=32, \n                      shuffle=True)\n\n# Validation DataLoader\nval_dl = DataLoader(val_ts,\n                    batch_size=32,\n                    shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:19.618994Z","iopub.execute_input":"2025-02-24T01:53:19.619201Z","iopub.status.idle":"2025-02-24T01:53:19.633410Z","shell.execute_reply.started":"2025-02-24T01:53:19.619173Z","shell.execute_reply":"2025-02-24T01:53:19.632665Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# check samples\nfor x,y in train_dl:\n    print(x.shape,y)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:19.634205Z","iopub.execute_input":"2025-02-24T01:53:19.634390Z","iopub.status.idle":"2025-02-24T01:53:19.860145Z","shell.execute_reply.started":"2025-02-24T01:53:19.634373Z","shell.execute_reply":"2025-02-24T01:53:19.859336Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def findConv2dOutShape(hin,win,conv,pool=2):\n    # get conv arguments\n    kernel_size=conv.kernel_size\n    stride=conv.stride\n    padding=conv.padding\n    dilation=conv.dilation\n\n    hout=np.floor((hin+2*padding[0]-dilation[0]*(kernel_size[0]-1)-1)/stride[0]+1)\n    wout=np.floor((win+2*padding[1]-dilation[1]*(kernel_size[1]-1)-1)/stride[1]+1)\n\n    if pool:\n        hout/=pool\n        wout/=pool\n    return int(hout),int(wout)\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# Neural Network\nclass Network(nn.Module):\n    \n    # Network Initialisation\n    def __init__(self, params):\n        \n        super(Network, self).__init__()\n    \n        Cin,Hin,Win=params[\"shape_in\"]\n        init_f=params[\"initial_filters\"] \n        num_fc1=params[\"num_fc1\"]  \n        num_classes=params[\"num_classes\"] \n        self.dropout_rate=params[\"dropout_rate\"] \n        \n        # Convolution Layers\n        self.conv1 = nn.Conv2d(Cin, init_f, kernel_size=3)\n        h,w=findConv2dOutShape(Hin,Win,self.conv1)\n        self.conv2 = nn.Conv2d(init_f, 2*init_f, kernel_size=3)\n        h,w=findConv2dOutShape(h,w,self.conv2)\n        self.conv3 = nn.Conv2d(2*init_f, 4*init_f, kernel_size=3)\n        h,w=findConv2dOutShape(h,w,self.conv3)\n        self.conv4 = nn.Conv2d(4*init_f, 8*init_f, kernel_size=3)\n        h,w=findConv2dOutShape(h,w,self.conv4)\n        \n        # compute the flatten size\n        self.num_flatten=h*w*8*init_f\n        self.fc1 = nn.Linear(self.num_flatten, num_fc1)\n        self.fc2 = nn.Linear(num_fc1, num_classes)\n\n    def forward(self,X):\n        \n        # Convolution & Pool Layers\n        X = F.relu(self.conv1(X)); \n        X = F.max_pool2d(X, 2, 2)\n        X = F.relu(self.conv2(X))\n        X = F.max_pool2d(X, 2, 2)\n        X = F.relu(self.conv3(X))\n        X = F.max_pool2d(X, 2, 2)\n        X = F.relu(self.conv4(X))\n        X = F.max_pool2d(X, 2, 2)\n\n        X = X.view(-1, self.num_flatten)\n        \n        X = F.relu(self.fc1(X))\n        X=F.dropout(X, self.dropout_rate)\n        X = self.fc2(X)\n        return F.log_softmax(X, dim=1)","metadata":{"_kg_hide-input":false,"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:19.860949Z","iopub.execute_input":"2025-02-24T01:53:19.861247Z","iopub.status.idle":"2025-02-24T01:53:19.870355Z","shell.execute_reply.started":"2025-02-24T01:53:19.861224Z","shell.execute_reply":"2025-02-24T01:53:19.869669Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Neural Network Predefined Parameters\nparams_model={\n        \"shape_in\": (3,46,46), \n        \"initial_filters\": 8,    \n        \"num_fc1\": 100,\n        \"dropout_rate\": 0.25,\n        \"num_classes\": 2}\n\n# Create instantiation of Network class\ncnn_model = Network(params_model)\n\n# define computation hardware approach (GPU/CPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = cnn_model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:19.871131Z","iopub.execute_input":"2025-02-24T01:53:19.871323Z","iopub.status.idle":"2025-02-24T01:53:20.104740Z","shell.execute_reply.started":"2025-02-24T01:53:19.871306Z","shell.execute_reply":"2025-02-24T01:53:20.103978Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchsummary import summary\nsummary(cnn_model, input_size=(3, 46, 46),device=device.type)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:20.105488Z","iopub.execute_input":"2025-02-24T01:53:20.105754Z","iopub.status.idle":"2025-02-24T01:53:20.726153Z","shell.execute_reply.started":"2025-02-24T01:53:20.105733Z","shell.execute_reply":"2025-02-24T01:53:20.725289Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loss_func = nn.NLLLoss(reduction=\"sum\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:20.726931Z","iopub.execute_input":"2025-02-24T01:53:20.727148Z","iopub.status.idle":"2025-02-24T01:53:20.739204Z","shell.execute_reply.started":"2025-02-24T01:53:20.727130Z","shell.execute_reply":"2025-02-24T01:53:20.738345Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch import optim\nopt = optim.Adam(cnn_model.parameters(), lr=3e-4)\nlr_scheduler = ReduceLROnPlateau(opt, mode='min',factor=0.5, patience=20,verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:20.740142Z","iopub.execute_input":"2025-02-24T01:53:20.740422Z","iopub.status.idle":"2025-02-24T01:53:20.764992Z","shell.execute_reply.started":"2025-02-24T01:53:20.740400Z","shell.execute_reply":"2025-02-24T01:53:20.764108Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"''' Helper Functions'''\n\n# Function to get the learning rate\ndef get_lr(opt):\n    for param_group in opt.param_groups:\n        return param_group['lr']\n\n# Function to compute the loss value per batch of data\ndef loss_batch(loss_func, output, target, opt=None):\n    \n    loss = loss_func(output, target) # get loss\n    pred = output.argmax(dim=1, keepdim=True) # Get Output Class\n    metric_b=pred.eq(target.view_as(pred)).sum().item() # get performance metric\n    \n    if opt is not None:\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n\n    return loss.item(), metric_b\n\n# Compute the loss value & performance metric for the entire dataset (epoch)\ndef loss_epoch(model,loss_func,dataset_dl,opt=None):\n    \n    run_loss=0.0 \n    t_metric=0.0\n    len_data=len(dataset_dl.dataset)\n\n    # internal loop over dataset\n    for xb, yb in dataset_dl:\n        # move batch to device\n        xb=xb.to(device)\n        yb=yb.to(device)\n        output=model(xb) # get model output\n        loss_b,metric_b=loss_batch(loss_func, output, yb, opt) # get loss per batch\n        run_loss+=loss_b        # update running loss\n\n        if metric_b is not None: # update running metric\n            t_metric+=metric_b    \n    \n    loss=run_loss/float(len_data)  # average loss value\n    metric=t_metric/float(len_data) # average metric value\n    \n    return loss, metric","metadata":{"_kg_hide-input":true,"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:20.765767Z","iopub.execute_input":"2025-02-24T01:53:20.766001Z","iopub.status.idle":"2025-02-24T01:53:20.781944Z","shell.execute_reply.started":"2025-02-24T01:53:20.765981Z","shell.execute_reply":"2025-02-24T01:53:20.781130Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"params_train={\n \"train\": train_dl,\"val\": val_dl,\n \"epochs\": 50,\n \"optimiser\": optim.Adam(cnn_model.parameters(),\n                         lr=3e-4),\n \"lr_change\": ReduceLROnPlateau(opt,\n                                mode='min',\n                                factor=0.5,\n                                patience=20,\n                                verbose=0),\n \"f_loss\": nn.NLLLoss(reduction=\"sum\"),\n \"weight_path\": \"weights.pt\",\n \"check\": False, \n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:20.782893Z","iopub.execute_input":"2025-02-24T01:53:20.783231Z","iopub.status.idle":"2025-02-24T01:53:20.802782Z","shell.execute_reply.started":"2025-02-24T01:53:20.783168Z","shell.execute_reply":"2025-02-24T01:53:20.802040Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm.notebook import trange, tqdm\n\ndef train_val(model, params,verbose=False):\n    \n    # Get the parameters\n    epochs=params[\"epochs\"]\n    loss_func=params[\"f_loss\"]\n    opt=params[\"optimiser\"]\n    train_dl=params[\"train\"]\n    val_dl=params[\"val\"]\n    lr_scheduler=params[\"lr_change\"]\n    weight_path=params[\"weight_path\"]\n    \n    loss_history={\"train\": [],\"val\": []} # history of loss values in each epoch\n    metric_history={\"train\": [],\"val\": []} # histroy of metric values in each epoch\n    best_model_wts = copy.deepcopy(model.state_dict()) # a deep copy of weights for the best performing model\n    best_loss=float('inf') # initialize best loss to a large value\n    \n    ''' Train Model n_epochs '''\n    \n    for epoch in tqdm(range(epochs)):\n        \n        ''' Get the Learning Rate '''\n        current_lr=get_lr(opt)\n        if(verbose):\n            print('Epoch {}/{}, current lr={}'.format(epoch, epochs - 1, current_lr))\n        \n        '''\n        \n        Train Model Process\n        \n        '''\n        \n        model.train()\n        train_loss, train_metric = loss_epoch(model,loss_func,train_dl,opt)\n\n        # collect losses\n        loss_history[\"train\"].append(train_loss)\n        metric_history[\"train\"].append(train_metric)\n        \n        '''\n        \n        Evaluate Model Process\n        \n        '''\n        \n        model.eval()\n        with torch.no_grad():\n            val_loss, val_metric = loss_epoch(model,loss_func,val_dl)\n        \n        # store best model\n        if(val_loss < best_loss):\n            best_loss = val_loss\n            best_model_wts = copy.deepcopy(model.state_dict())\n            \n            # store weights into a local file\n            torch.save(model.state_dict(), weight_path)\n            if(verbose):\n                print(\"Copied best model weights!\")\n        \n        # collect loss and metric for validation dataset\n        loss_history[\"val\"].append(val_loss)\n        metric_history[\"val\"].append(val_metric)\n        \n        # learning rate schedule\n        lr_scheduler.step(val_loss)\n        if current_lr != get_lr(opt):\n            if(verbose):\n                print(\"Loading best model weights!\")\n            model.load_state_dict(best_model_wts) \n\n        if(verbose):\n            print(f\"train loss: {train_loss:.6f}, dev loss: {val_loss:.6f}, accuracy: {100*val_metric:.2f}\")\n            print(\"-\"*10) \n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n        \n    return model, loss_history, metric_history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:20.803576Z","iopub.execute_input":"2025-02-24T01:53:20.803864Z","iopub.status.idle":"2025-02-24T01:53:20.939093Z","shell.execute_reply.started":"2025-02-24T01:53:20.803843Z","shell.execute_reply":"2025-02-24T01:53:20.938425Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"params_train={\n \"train\": train_dl,\"val\": val_dl,\n \"epochs\": 50,\n \"optimiser\": optim.Adam(cnn_model.parameters(),lr=3e-4),\n \"lr_change\": ReduceLROnPlateau(opt,\n                                mode='min',\n                                factor=0.5,\n                                patience=20,\n                                verbose=0),\n \"f_loss\": nn.NLLLoss(reduction=\"sum\"),\n \"weight_path\": \"weights.pt\",\n}\n\n''' Actual Train / Evaluation of CNN Model '''\n# train and validate the model\n\ncnn_model,loss_hist,metric_hist=train_val(cnn_model,params_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:53:20.939919Z","iopub.execute_input":"2025-02-24T01:53:20.940123Z","iopub.status.idle":"2025-02-24T01:58:55.593836Z","shell.execute_reply.started":"2025-02-24T01:53:20.940105Z","shell.execute_reply":"2025-02-24T01:58:55.592872Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"script_model = torch.jit.script(cnn_model)\nscript_model.save('skin_cancer.pt') ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T02:10:28.777498Z","iopub.execute_input":"2025-02-24T02:10:28.777872Z","iopub.status.idle":"2025-02-24T02:10:28.860807Z","shell.execute_reply.started":"2025-02-24T02:10:28.777843Z","shell.execute_reply":"2025-02-24T02:10:28.859913Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns; sns.set(style='whitegrid')\n\nepochs=params_train[\"epochs\"]\n\nfig,ax = plt.subplots(1,2,figsize=(12,5))\n\nsns.lineplot(x=[*range(1,epochs+1)],y=loss_hist[\"train\"],ax=ax[0],label='loss_hist[\"train\"]')\nsns.lineplot(x=[*range(1,epochs+1)],y=loss_hist[\"val\"],ax=ax[0],label='loss_hist[\"val\"]')\nsns.lineplot(x=[*range(1,epochs+1)],y=metric_hist[\"train\"],ax=ax[1],label='metric_hist[\"train\"]')\nsns.lineplot(x=[*range(1,epochs+1)],y=metric_hist[\"val\"],ax=ax[1],label='metric_hist[\"val\"]')\nplt.title('Convergence History')","metadata":{"_kg_hide-input":true,"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:58:55.594630Z","iopub.execute_input":"2025-02-24T01:58:55.594929Z","iopub.status.idle":"2025-02-24T01:58:56.691722Z","shell.execute_reply.started":"2025-02-24T01:58:55.594893Z","shell.execute_reply":"2025-02-24T01:58:56.690841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Train-Validation Progress\n# epochs=params_train[\"epochs\"]\n\n# fig = make_subplots(rows=1, cols=2,subplot_titles=['lost_hist','metric_hist'])\n# fig.add_trace(go.Scatter(x=[*range(1,epochs+1)], y=loss_hist[\"train\"],name='loss_hist[\"train\"]'),row=1, col=1)\n# fig.add_trace(go.Scatter(x=[*range(1,epochs+1)], y=loss_hist[\"val\"],name='loss_hist[\"val\"]'),row=1, col=1)\n# fig.add_trace(go.Scatter(x=[*range(1,epochs+1)], y=metric_hist[\"train\"],name='metric_hist[\"train\"]'),row=1, col=2)\n# fig.add_trace(go.Scatter(x=[*range(1,epochs+1)], y=metric_hist[\"val\"],name='metric_hist[\"val\"]'),row=1, col=2)\n# fig.update_layout(template='plotly_white');fig.update_layout(margin={\"r\":0,\"t\":60,\"l\":0,\"b\":0},height=300)\n# fig.show()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:58:56.692620Z","iopub.execute_input":"2025-02-24T01:58:56.693199Z","iopub.status.idle":"2025-02-24T01:58:56.696470Z","shell.execute_reply.started":"2025-02-24T01:58:56.693166Z","shell.execute_reply":"2025-02-24T01:58:56.695613Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class pytorchdata_test(Dataset):\n    \n    def __init__(self, data_dir, transform,data_type=\"train\"):\n        \n        path2data = os.path.join(data_dir,data_type)\n        filenames = os.listdir(path2data)\n        self.full_filenames = [os.path.join(path2data, f) for f in filenames]\n        \n        # labels are in a csv file named train_labels.csv\n        csv_filename=\"sample_submission.csv\"\n        path2csvLabels=os.path.join(data_dir,csv_filename)\n        labels_df=pd.read_csv(path2csvLabels)\n        \n        # set data frame index to id\n        labels_df.set_index(\"id\", inplace=True)\n        \n        # obtain labels from data frame\n        self.labels = [labels_df.loc[filename[:-4]].values[0] for filename in filenames]\n        self.transform = transform       \n        \n    def __len__(self):\n        # return size of dataset\n        return len(self.full_filenames)\n    \n    def __getitem__(self, idx):\n        # open image, apply transforms and return with label\n        image = Image.open(self.full_filenames[idx]) # PIL image\n        image = self.transform(image)\n        return image, self.labels[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:58:56.697391Z","iopub.execute_input":"2025-02-24T01:58:56.697700Z","iopub.status.idle":"2025-02-24T01:58:56.718762Z","shell.execute_reply.started":"2025-02-24T01:58:56.697671Z","shell.execute_reply":"2025-02-24T01:58:56.717922Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:58:56.719587Z","iopub.execute_input":"2025-02-24T01:58:56.719853Z","iopub.status.idle":"2025-02-24T01:58:56.876577Z","shell.execute_reply.started":"2025-02-24T01:58:56.719832Z","shell.execute_reply":"2025-02-24T01:58:56.875781Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls '/kaggle/input/histopathologic-cancer-detection/test' | head -n 5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:58:56.877641Z","iopub.execute_input":"2025-02-24T01:58:56.877957Z","iopub.status.idle":"2025-02-24T01:58:57.777774Z","shell.execute_reply.started":"2025-02-24T01:58:56.877920Z","shell.execute_reply":"2025-02-24T01:58:57.776835Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# load any model weights for the model\ncnn_model.load_state_dict(torch.load('weights.pt'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:58:57.782890Z","iopub.execute_input":"2025-02-24T01:58:57.783130Z","iopub.status.idle":"2025-02-24T01:58:57.794377Z","shell.execute_reply.started":"2025-02-24T01:58:57.783109Z","shell.execute_reply":"2025-02-24T01:58:57.793578Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# sample submission\npath_sub = \"/kaggle/input/histopathologic-cancer-detection/sample_submission.csv\"\nlabels_df = pd.read_csv(path_sub)\nlabels_df.head()\nlabels_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:58:57.795645Z","iopub.execute_input":"2025-02-24T01:58:57.795872Z","iopub.status.idle":"2025-02-24T01:58:57.927015Z","shell.execute_reply.started":"2025-02-24T01:58:57.795853Z","shell.execute_reply":"2025-02-24T01:58:57.926283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_dir = '/kaggle/input/histopathologic-cancer-detection/'\n\ndata_transformer = transforms.Compose([transforms.ToTensor(),\n                                       transforms.Resize((46,46))])\n\nimg_dataset_test = pytorchdata_test(data_dir,data_transformer,data_type=\"test\")\nprint(len(img_dataset_test), 'samples found')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:58:57.927796Z","iopub.execute_input":"2025-02-24T01:58:57.928092Z","iopub.status.idle":"2025-02-24T01:58:59.265095Z","shell.execute_reply.started":"2025-02-24T01:58:57.928070Z","shell.execute_reply":"2025-02-24T01:58:59.263926Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def inference(model,dataset,device,num_classes=2):\n    \n    len_data=len(dataset)\n    y_out=torch.zeros(len_data,num_classes) # initialize output tensor on CPU\n    y_gt=np.zeros((len_data),dtype=\"uint8\") # initialize ground truth on CPU\n    model=model.to(device) # move model to device\n    \n    with torch.no_grad():\n        for i in tqdm(range(len_data)):\n            x,y=dataset[i]\n            y_gt[i]=y\n            y_out[i]=model(x.unsqueeze(0).to(device))\n\n    return y_out.numpy(),y_gt            ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:58:59.266057Z","iopub.execute_input":"2025-02-24T01:58:59.266396Z","iopub.status.idle":"2025-02-24T01:58:59.273809Z","shell.execute_reply.started":"2025-02-24T01:58:59.266362Z","shell.execute_reply":"2025-02-24T01:58:59.272391Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_test_out,_ = inference(cnn_model,img_dataset_test, device)            ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T01:58:59.274954Z","iopub.execute_input":"2025-02-24T01:58:59.275328Z","iopub.status.idle":"2025-02-24T02:07:57.664166Z","shell.execute_reply.started":"2025-02-24T01:58:59.275290Z","shell.execute_reply":"2025-02-24T02:07:57.663279Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# class predictions 0,1\ny_test_pred=np.argmax(y_test_out,axis=1)\nprint(y_test_pred.shape)\nprint(y_test_pred[0:5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T02:07:57.665005Z","iopub.execute_input":"2025-02-24T02:07:57.665302Z","iopub.status.idle":"2025-02-24T02:07:57.670709Z","shell.execute_reply.started":"2025-02-24T02:07:57.665273Z","shell.execute_reply":"2025-02-24T02:07:57.669973Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# probabilities of predicted selection\n# return F.log_softmax(x, dim=1) ie.\npreds = np.exp(y_test_out[:, 1])\nprint(preds.shape)\nprint(preds[0:5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T02:07:57.671416Z","iopub.execute_input":"2025-02-24T02:07:57.671763Z","iopub.status.idle":"2025-02-24T02:07:57.686561Z","shell.execute_reply.started":"2025-02-24T02:07:57.671724Z","shell.execute_reply":"2025-02-24T02:07:57.685939Z"}},"outputs":[],"execution_count":null}]}