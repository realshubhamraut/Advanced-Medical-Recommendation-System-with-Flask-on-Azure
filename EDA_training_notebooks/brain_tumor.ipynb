{
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 2236708,
          "sourceType": "datasetVersion",
          "datasetId": 1343913
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "notebook13962bc84d",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/realshubhamraut/Advanced-Medical-Recommendation-System-with-Flask-on-Azure/blob/main/EDA_training_notebooks/brain_tumor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b> Convolutional Neural Network for Brain Tumor Detection and Diagnosis (Pytorch, F1-score: 0.97) </b>"
      ],
      "metadata": {
        "id": "7cRFuBmAK18a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set(style='darkgrid')\n",
        "import copy\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torch.nn as nn\n",
        "from torchvision import utils\n",
        "from torchvision.datasets import ImageFolder\n",
        "import splitfolders\n",
        "from torchsummary import summary\n",
        "import torch.nn.functional as F\n",
        "import pathlib\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "from tqdm.notebook import trange, tqdm\n",
        "from torch import optim\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "wCFnGJFRK18b"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "# metadata_path = '../datasets/brain_tumor_data/metadata.csv'\n",
        "# labels_df = pd.read_csv(metadata_path)\n",
        "# print(labels_df.head().to_markdown())\n",
        "# print(\"Shape:\", labels_df.shape)"
      ],
      "metadata": {
        "id": "2zCf_IjZK18c"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import os\n",
        "\n",
        "data_dir = '../datasets/brain_tumor_data'\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "print(\"Files in dataset directory:\", os.listdir(str(data_dir)))"
      ],
      "metadata": {
        "id": "Y5UFyqENK18c",
        "outputId": "d9cf5ba5-d991-4654-f17a-1256bdcd564d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../datasets/brain_tumor_data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a0ab8b7525d4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../datasets/brain_tumor_data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Files in dataset directory:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../datasets/brain_tumor_data'"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_j2nAdDZMIE4",
        "outputId": "9b69aed1-b58c-40f5-fc81-e40b8d5419b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splitfolders.ratio(str(data_dir), output='brain', seed=20, ratio=(0.8, 0.2))\n"
      ],
      "metadata": {
        "id": "O9RIpa-UK18c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = pathlib.Path('brain')\n",
        "print(\"Split dataset available at:\", data_dir)"
      ],
      "metadata": {
        "id": "iN3LgzJCK18c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256,256)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "qXtoRW1xK18d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = torchvision.datasets.ImageFolder(data_dir.joinpath(\"train\"), transform=transform)\n",
        "val_set = torchvision.datasets.ImageFolder(data_dir.joinpath(\"val\"), transform=transform)\n"
      ],
      "metadata": {
        "id": "yLWb4FBzK18d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "CLA_label = {0: 'Brain Tumor', 1: 'Healthy'}\n",
        "figure = plt.figure(figsize=(10, 10))\n",
        "cols, rows = 4, 4\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_set), size=(1,)).item()\n",
        "    img, label = train_set[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(CLA_label[label])\n",
        "    plt.axis(\"off\")\n",
        "    img_np = img.numpy().transpose((1, 2, 0))\n",
        "    # Clip pixel values to [0, 1]\n",
        "    img_valid_range = np.clip(img_np, 0, 1)\n",
        "    plt.imshow(img_valid_range)\n",
        "    plt.suptitle('Brain Images', y=0.95)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8AAGFzo0K18d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "for key, value in {'Training data': train_loader, \"Validation data\": val_loader}.items():\n",
        "    for X, y in value:\n",
        "        print(f\"{key}:\")\n",
        "        print(f\"Shape of X : {X.shape}\")\n",
        "        print(f\"Shape of y: {y.shape} {y.dtype}\\n\")\n",
        "        break\n"
      ],
      "metadata": {
        "id": "X0VksJuaK18d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def findConv2dOutShape(hin, win, conv, pool=2):\n",
        "    kernel_size = conv.kernel_size\n",
        "    stride = conv.stride\n",
        "    padding = conv.padding\n",
        "    dilation = conv.dilation\n",
        "    hout = np.floor((hin + 2 * padding[0] - dilation[0]*(kernel_size[0]-1) - 1) / stride[0] + 1)\n",
        "    wout = np.floor((win + 2 * padding[1] - dilation[1]*(kernel_size[1]-1) - 1) / stride[1] + 1)\n",
        "    if pool:\n",
        "        hout /= pool\n",
        "        wout /= pool\n",
        "    return int(hout), int(wout)"
      ],
      "metadata": {
        "id": "Bm3m42NJK18e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN Architecture For Brain Tumor Model\n",
        "# ----------------------------\n",
        "class CNN_TUMOR(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(CNN_TUMOR, self).__init__()\n",
        "        Cin, Hin, Win = params[\"shape_in\"]\n",
        "        init_f = params[\"initial_filters\"]\n",
        "        num_fc1 = params[\"num_fc1\"]\n",
        "        num_classes = params[\"num_classes\"]\n",
        "        self.dropout_rate = params[\"dropout_rate\"]\n",
        "\n",
        "        self.conv1 = nn.Conv2d(Cin, init_f, kernel_size=3)\n",
        "        h, w = findConv2dOutShape(Hin, Win, self.conv1)\n",
        "        self.conv2 = nn.Conv2d(init_f, 2 * init_f, kernel_size=3)\n",
        "        h, w = findConv2dOutShape(h, w, self.conv2)\n",
        "        self.conv3 = nn.Conv2d(2 * init_f, 4 * init_f, kernel_size=3)\n",
        "        h, w = findConv2dOutShape(h, w, self.conv3)\n",
        "        self.conv4 = nn.Conv2d(4 * init_f, 8 * init_f, kernel_size=3)\n",
        "        h, w = findConv2dOutShape(h, w, self.conv4)\n",
        "\n",
        "        self.num_flatten = h * w * 8 * init_f\n",
        "        self.fc1 = nn.Linear(self.num_flatten, num_fc1)\n",
        "        self.fc2 = nn.Linear(num_fc1, num_classes)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = F.relu(self.conv1(X))\n",
        "        X = F.max_pool2d(X, 2, 2)\n",
        "        X = F.relu(self.conv2(X))\n",
        "        X = F.max_pool2d(X, 2, 2)\n",
        "        X = F.relu(self.conv3(X))\n",
        "        X = F.max_pool2d(X, 2, 2)\n",
        "        X = F.relu(self.conv4(X))\n",
        "        X = F.max_pool2d(X, 2, 2)\n",
        "        X = X.view(-1, self.num_flatten)\n",
        "        X = F.relu(self.fc1(X))\n",
        "        X = F.dropout(X, self.dropout_rate)\n",
        "        X = self.fc2(X)\n",
        "        return F.log_softmax(X, dim=1)\n",
        "\n",
        "params_model = {\n",
        "    \"shape_in\": (3, 256, 256),\n",
        "    \"initial_filters\": 8,\n",
        "    \"num_fc1\": 100,\n",
        "    \"dropout_rate\": 0.25,\n",
        "    \"num_classes\": 2\n",
        "}"
      ],
      "metadata": {
        "id": "A3_PTLGYK18e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = CNN_TUMOR(params_model)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "cnn_model = cnn_model.to(device)\n",
        "\n",
        "summary(cnn_model, input_size=(3, 256, 256), device=device.type)\n",
        "\n",
        "loss_func = nn.NLLLoss(reduction=\"sum\")\n",
        "opt = optim.Adam(cnn_model.parameters(), lr=3e-4)\n",
        "lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=20, verbose=1)\n"
      ],
      "metadata": {
        "id": "UUH3396XK18e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lr(opt):\n",
        "    for param_group in opt.param_groups:\n",
        "        return param_group['lr']\n"
      ],
      "metadata": {
        "id": "vHBPBR5OK18e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def loss_batch(loss_func, output, target, opt=None):\n",
        "    loss = loss_func(output, target)\n",
        "    pred = output.argmax(dim=1, keepdim=True)\n",
        "    metric_b = pred.eq(target.view_as(pred)).sum().item()\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "    return loss.item(), metric_b"
      ],
      "metadata": {
        "id": "jcx-zfDCK18e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_epoch(model, loss_func, dataset_dl, opt=None):\n",
        "    run_loss = 0.0\n",
        "    t_metric = 0.0\n",
        "    len_data = len(dataset_dl.dataset)\n",
        "    for xb, yb in dataset_dl:\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "        output = model(xb)\n",
        "        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
        "        run_loss += loss_b\n",
        "        if metric_b is not None:\n",
        "            t_metric += metric_b\n",
        "    loss_val = run_loss / float(len_data)\n",
        "    metric_val = t_metric / float(len_data)\n",
        "    return loss_val, metric_val"
      ],
      "metadata": {
        "id": "hPv-2tU1K18e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def Train_Val(model, params, verbose=False):\n",
        "    epochs = params[\"epochs\"]\n",
        "    loss_func = params[\"f_loss\"]\n",
        "    opt = params[\"optimiser\"]\n",
        "    train_dl = params[\"train\"]\n",
        "    val_dl = params[\"val\"]\n",
        "    lr_scheduler = params[\"lr_change\"]\n",
        "    weight_path = params[\"weight_path\"]\n",
        "\n",
        "    loss_history = {\"train\": [], \"val\": []}\n",
        "    metric_history = {\"train\": [], \"val\": []}\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        current_lr = get_lr(opt)\n",
        "        if(verbose):\n",
        "            print('Epoch {}/{}, current lr={}'.format(epoch, epochs - 1, current_lr))\n",
        "\n",
        "        model.train()\n",
        "        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, opt)\n",
        "        loss_history[\"train\"].append(train_loss)\n",
        "        metric_history[\"train\"].append(train_metric)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_metric = loss_epoch(model, loss_func, val_dl)\n",
        "\n",
        "        if(val_loss < best_loss):\n",
        "            best_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            torch.save(model.state_dict(), weight_path)\n",
        "            if verbose:\n",
        "                print(\"Copied best model weights!\")\n",
        "\n",
        "        loss_history[\"val\"].append(val_loss)\n",
        "        metric_history[\"val\"].append(val_metric)\n",
        "        lr_scheduler.step(val_loss)\n",
        "        if current_lr != get_lr(opt):\n",
        "            if verbose:\n",
        "                print(\"Loading best model weights!\")\n",
        "            model.load_state_dict(best_model_wts)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"train loss: {train_loss:.6f}, dev loss: {val_loss:.6f}, accuracy: {100*val_metric:.2f}\")\n",
        "            print(\"-\"*10)\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, loss_history, metric_history"
      ],
      "metadata": {
        "id": "j0wjU4yKK18f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "params_train = {\n",
        "    \"train\": train_loader,\n",
        "    \"val\": val_loader,\n",
        "    \"epochs\": 60,\n",
        "    \"optimiser\": optim.Adam(cnn_model.parameters(), lr=3e-4),\n",
        "    \"lr_change\": ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=20, verbose=0),\n",
        "    \"f_loss\": nn.NLLLoss(reduction=\"sum\"),\n",
        "    \"weight_path\": \"weights.pt\",\n",
        "}"
      ],
      "metadata": {
        "id": "HE3mTfXYK18f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model, loss_hist, metric_hist = Train_Val(cnn_model, params_train)\n",
        "\n",
        "epochs = params_train[\"epochs\"]\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "sns.lineplot(x=list(range(1, epochs+1)), y=loss_hist[\"train\"], ax=ax[0], label='Train Loss')\n",
        "sns.lineplot(x=list(range(1, epochs+1)), y=loss_hist[\"val\"], ax=ax[0], label='Val Loss')\n",
        "sns.lineplot(x=list(range(1, epochs+1)), y=metric_hist[\"train\"], ax=ax[1], label='Train Accuracy')\n",
        "sns.lineplot(x=list(range(1, epochs+1)), y=metric_hist[\"val\"], ax=ax[1], label='Val Accuracy')\n",
        "\n",
        "def Ture_and_Pred(val_loader, model):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for images, labels in val_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.numpy()\n",
        "        outputs = model(images)\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        pred = pred.detach().cpu().numpy()\n",
        "        y_true = np.append(y_true, labels)\n",
        "        y_pred = np.append(y_pred, pred)\n",
        "    return y_true, y_pred"
      ],
      "metadata": {
        "id": "ODnkLOs4K18f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "y_true, y_pred = Ture_and_Pred(val_loader, cnn_model)\n",
        "print(classification_report(y_true, y_pred), '\\n\\n')\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "def show_confusion_matrix(cm, CLA_label, title='Confusion matrix', cmap=plt.cm.YlGnBu):\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.grid(False)\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(CLA_label))\n",
        "    plt.xticks(tick_marks, [f\"{value}={key}\" for key, value in CLA_label.items()], rotation=45)\n",
        "    plt.yticks(tick_marks, [f\"{value}={key}\" for key, value in CLA_label.items()])\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, f\"{cm[i, j]}\\n{cm[i, j]/np.sum(cm)*100:.2f}%\",\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "rvjlpT1gK18f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "show_confusion_matrix(cm, CLA_label)\n",
        "torch.save(cnn_model, \"../models/Brain_Tumor_model.pt\")"
      ],
      "metadata": {
        "id": "X3TQ-UOVK18f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Qes5gNjsK18g"
      }
    }
  ]
}